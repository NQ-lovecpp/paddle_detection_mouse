
gpu direct、nccl、rdma、tcp套接字

<!--
# 工作目标

1. **下载与Paddle-GPU训练框架版本相适应的PaddleDetection源码**
   - 目标：确保能够快速完成交通标志的模型训练（支持单双卡）
   - 步骤：
     1. 确认想要使用的PaddlePaddle-GPU版本。
     2. 从PaddleDetection官方仓库下载与Paddle-GPU版本相匹配的源码。
     3. 配置环境，确保PaddleDetection在单卡和多卡环境下都能正常运行。

2. **形成记录文档或PPT，记录包括环境搭建，训练过程中遇到的问题及解决方法**
   - 目标：完整记录整个过程，形成可供后续参考的文档或PPT。
   - 步骤：
     1. 环境搭建：记录所需的软件和硬件环境，详细步骤和配置方法。
     2. 训练过程：记录训练过程中遇到的问题及详细解决方法，包括代码修改、参数调整等。
     3. 总结：总结整个训练过程中的经验和教训，提出优化建议。

3. **根据README以及自己在工程过程中发现的兴趣点，做出有意义的注释**
   - 目标：在README的基础上添加自己在工程过程中发现的兴趣点和有意义的注释，便于理解和使用。
   - 步骤：
     1. 阅读和理解PaddleDetection的README文件。
     2. 在README的基础上，补充自己在实际操作过程中发现的有用信息和心得体会。
     3. 在代码中添加注释，解释关键部分的逻辑和实现原理。

-->

# 一、搭建PaddleDetection依赖的环境

## PaddleDetection2.7对服务器环境的要求
| paddledetection2.7的要求 | 本文档的选择 |
| ---- | ---- |
| PaddlePaddle2.3.2以上 | paddlepaddle-gpu 2.6.1.post120 |
| 64位操作系统 | Ubuntu 20.04 |
| Python 3 (3.5.1+/3.6/3.7/3.8/3.9/3.10)，64位版本 | Python 3.10 |
| pip/pip3 (9.0.1+)，64位版本 | pip 20.0.2 |
| CUDA >= 10.2 | CUDA 12.0 |
| cuDNN >= 7.6 | cuDNN 8.8.0.121 |


>由于PaddleDetection是基于PaddlePaddle的一个分支，所以存在两者的依赖关系，具体如下表

| PaddleDetection版本 | PaddlePaddle版本 |    备注     |
| :---------------: | :------------: | :-------: |
|      develop      |    >=2.3.2     | 默认使用动态图模式 |
|  **release/2.6**  |  **>=2.3.2**   | 默认使用动态图模式 |
|    release/2.5    |    >= 2.2.2    | 默认使用动态图模式 |
|    release/2.4    |    >= 2.2.2    | 默认使用动态图模式 |
|    release/2.3    |   >= 2.2.0rc   | 默认使用动态图模式 |
|    release/2.2    |    >= 2.1.2    | 默认使用动态图模式 |
|    release/2.1    |    >= 2.1.0    | 默认使用动态图模式 |
|    release/2.0    |    >= 2.0.1    | 默认使用动态图模式 |
>本文档选择**PaddleDetection**版本为**release/2.7**，所以PaddlePaddle版本应该选择**2.3.2以上**，本文以**PaddlePaddle2.6.1**为例

## 检查并安装环境

### 查看服务器的系统信息
首先，我们有必要先检查当前服务器的系统信息，包括内核版本、硬件配置等，有助于我们了解服务器配置。可以使用以下命令查看**处理器的架构**、**Linux发行版版本**和**Nvidia显卡信息**：

```bash
uname -m && cat /etc/*release
nvidia-smi
```

### 切换软件源

>[!Question] 为什么要切换默认的软件源
>
>切换apt的软件源为国内源可以显著提高软件包下载和更新的速度，尤其是对于国内用户而言。国内的镜像源如清华源和阿里云源通常更快、更稳定，能够提供更好的用户体验。下面介绍如何在Ubuntu系统中将APT的软件源切换为清华源或阿里云源。
#### 切换为清华源

1. 备份原有的sources.list文件：
   ```bash
   sudo cp /etc/apt/sources.list /etc/apt/sources.list.backup
   ```

2. 编辑sources.list文件：
   ```bash
   sudo nano /etc/apt/sources.list
   ```

3. 替换为清华源，在文件中粘贴以下内容：
   ```plaintext
   deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse
   deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse
   deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse
   deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse
   ```

4. 保存并关闭文件（按Ctrl+O，然后按Enter保存，按Ctrl+X退出）。

5. 更新软件包列表：
   ```bash
   sudo apt update
   ```

#### 切换为阿里云源

1. 备份原有的sources.list文件：
   ```bash
   sudo cp /etc/apt/sources.list /etc/apt/sources.list.backup
   ```

2. 编辑sources.list文件：
   ```bash
   sudo nano /etc/apt/sources.list
   ```

3. 替换为阿里云源，在文件中粘贴以下内容：
   ```plaintext
   deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse
   deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse
   deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse
   deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse
   deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse
   ```

4. 保存并关闭文件（按Ctrl+O，然后按Enter保存，按Ctrl+X退出）。

5. 更新软件包列表：
   ```bash
   sudo apt update
   ```

通过以上步骤，可以将APT软件源切换为国内的清华源或阿里云源，从而提高软件包下载和更新的速度。


### 安装Python3

PaddlePaddle支持的**Python版本为3.7/3.8/3.9/3.10/3.11**，这里以安装Python3.10为例
```bash
# 查询可用的Python 3.10版本
sudo apt update
sudo apt list python3.10
```

>[!Tip] 这里可能会出现找不到python包的情况：
> 
>```bash
>developer@ubuntu-server:/etc/apt$ sudo apt list python3.10
>Listing... Done
>developer@ubuntu-server:/etc/apt$ sudo apt install python3.10 python3.10-venv python3.10-dev -yReading package lists... Done
>Building dependency tree       
>Reading state information... Done
>E: Unable to locate package python3.10
>E: Couldn't find any package by glob 'python3.10'
>E: Unable to locate package python3.10-venv
>E: Couldn't find any package by glob 'python3.10-venv'
>E: Unable to locate package python3.10-dev
>E: Couldn't find any package by glob 'python3.10-dev'
>```
>
>解决方法如下：
>
>1. 安装 `software-properties-common` 包：
>
>	```shell
>	sudo apt update
>	sudo apt install software-properties-common -y
>	```
>
>2. 然后再尝试添加 `deadsnakes` PPA：
>
>	```shell
>	sudo add-apt-repository ppa:deadsnakes/ppa
>	sudo apt update
>	```

```
# 安装Python 3.10
sudo apt install python3.10 python3.10-venv python3.10-dev -y
```

>因为您计算机可能有多个 Python，需要让`python3`指向刚才安装的python3.10

```
# 设置python3指向python3.10
sudo mv /usr/bin/python3 /usr/bin/python3.bak
sudo ln -s /usr/bin/python3.10 /usr/bin/python3
```

```
# 验证安装
python3 --version
```

效果如下：
![[Pasted image 20240802093601.png]]


根据您的环境您可能需要将说明中所有命令行中的 python3 替换为具体的 Python 路径

```bash
which python3
```


>确认Python和Pip的架构

需要确认 Python 和 pip 是 64bit，并且处理器架构是 x86_64（或称作 x64、Intel 64、AMD64）架构。下面的第一行输出的是”64bit”，第二行输出的是”x86_64”、”x64”或”AMD64”即可：

```bash
python3 -c "import platform;print(platform.architecture([0]);print(platform.machine())"
```




### 安装Pip
Pip是Python的包管理工具，安装步骤如下：

```bash
# 更新包索引
sudo apt update

# 安装pip
sudo apt install python3-pip -y

# 验证安装
pip3 --version
```


为了确保最佳兼容性和性能，最好验证PaddlePaddle是否官方支持这种组合。

你可以按照以下步骤安装并配置CUDA 12.0和cuDNN 8.8.0.121：



### 安装CUDA 12.0

请使用Nvidia官网的安装教程：
https://developer.nvidia.com/cuda-12-0-0-download-archive?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=deb_local

示例：
```bash
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pinsudo 

mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600wget https://developer.download.nvidia.com/compute/cuda/12.3.0/local_installers/cuda-repo-ubuntu2004-12-3-local_12.3.0-545.23.06-1_amd64.debsudo 

dpkg -i cuda-repo-ubuntu2004-12-3-local_12.3.0-545.23.06-1_amd64.deb

sudo cp /var/cuda-repo-ubuntu2004-12-3-local/cuda-*-keyring.gpg /usr/share/keyrings/sudo apt-get update

sudo apt-get -y install cuda-toolkit-12-3
```


**验证安装**
```bash
nvcc --version

# 输出：
developer@ubuntu-server:~/third_party$ nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2023 NVIDIA Corporation
Built on Fri_Sep__8_19:17:24_PDT_2023
Cuda compilation tools, release 12.3, V12.3.52
Build cuda_12.3.r12.3/compiler.33281558_0
```


配置环境变量：
```bash
echo 'export PATH=/usr/local/cuda-12.3/bin:$PATH' >> ~/.bashrc 
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.3/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc 
source ~/.bashrc
```


### 安装cuDNN 9.0.0

和cuda一样，参考官方安装指南：
https://developer.nvidia.com/cudnn-9-0-0-download-archive?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=deb_local

示例：
```bash
# Installation Instructions:
wget https://developer.download.nvidia.com/compute/cudnn/9.0.0/local_installers/cudnn-local-repo-ubuntu2004-9.0.0_1.0-1_amd64.deb

sudo dpkg -i cudnn-local-repo-ubuntu2004-9.0.0_1.0-1_amd64.deb
sudo cp /var/cudnn-local-repo-ubuntu2004-9.0.0/cudnn-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cudnn

# To install for CUDA 11, perform the above configuration but install the CUDA 11 specific package:
sudo apt-get -y install cudnn-cuda-11

# To install for CUDA 12, perform the above configuration but install the CUDA 12 specific package:
sudo apt-get -y install cudnn-cuda-12
```


### 安装TensorRT 8.6.1.6（可选）

1. **下载并解压TensorRT**
   ```bash
   tar -xvzf TensorRT-8.6.1.6.Ubuntu-20.04.x86_64-gnu.cuda-12.3.cudnn8.9.tar.gz
   cd TensorRT-8.6.1.6
   sudo cp lib/* /usr/local/lib
   sudo cp include/* /usr/local/include
   ```

2. **配置环境变量**
   ```bash
   echo 'export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH' >> ~/.bashrc
   source ~/.bashrc
   ```

3. **验证安装**
   ```bash
   ls /usr/local/lib | grep nvinfer
   ```


### 安装PaddlePaddle

>[!Attention] 注意：
>- 务必确保与[PaddlePaddle官网](https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/pip/linux-pip.html)的配置要求一致

确保你的环境配置正确，接下来可以安装PaddlePaddle：

```bash
python -m pip install paddlepaddle-gpu==2.6.1.post120 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html
```

使用下面的python脚本验证PaddlePaddle是能够正常工作：
```python
# 在您的Python解释器中确认PaddlePaddle安装成功
import paddle
paddle.utils.run_check()

# 确认PaddlePaddle版本
import paddle
print(paddle.__version__)
```
![[Pasted image 20240805095955.png]]


### 安装NCCL（多卡环境）
>[!Attention] **注意**
>
>- 如果您希望在多卡环境下使用PaddleDetection，请首先安装NCCL

务必参考官方指南：
https://developer.nvidia.com/nccl/nccl-legacy-downloads

示例：
```bash
Network Installer for Ubuntu22.04

- $ wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb
- $ sudo dpkg -i cuda-keyring_1.0-1_all.deb
- $ sudo apt-get update

Network Installer for Ubuntu20.04

- $ wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb
- $ sudo dpkg -i cuda-keyring_1.0-1_all.deb
- $ sudo apt-get update

Network Installer for RedHat/CentOS 9

- $ sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/cuda-rhel9.repo

Network Installer for RedHat/CentOS 8

- $ sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo

Network Installer for RedHat/CentOS 7

- $ sudo yum-config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel7/x86_64/cuda-rhel7.repo
```


# 二、下载与配置PaddleDetection源码

克隆paddledetection的源代码到服务器，并切换到`release/2.7`分支：
```bash
git clone https://github.com/PaddlePaddle/PaddleDetection.git
cd PaddleDetection
git checkout release/2.7
```

安装依赖：
```bash
# 安装其他依赖
cd PaddleDetection
pip install -r requirements.txt

# 编译安装paddledet，这里必须使用sudo提权，因为要安装到系统目录
sudo python setup.py install
```

>[!Attention] **注意**
>
>1. 如果github下载代码较慢，可尝试使用[gitee](https://gitee.com/PaddlePaddle/PaddleDetection.git)或者[代理加速](https://doc.fastgit.org/zh-cn/guide.html)。
>    
>2. 若您使用的是Windows系统，由于原版cocoapi不支持Windows，`pycocotools`依赖可能安装失败，可采用第三方实现版本，该版本仅支持Python3
>    ```bash
>    pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI
>    ```
>    
>3. 若您使用的是Python <= 3.6的版本，安装`pycocotools`可能会报错`distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('cython>=0.27.3')`, 您可通过先安装`cython`如`pip install cython`解决该问题


安装后确认测试通过：
```bash
python ppdet/modeling/tests/test_architectures.py
```

测试通过后会提示如下信息：
```
.......
----------------------------------------------------------------------
Ran 7 tests in 12.816s
OK
```


# 三、快速体验 - 推理

**恭喜！** 您已经成功安装了PaddleDetection，接下来快速体验目标检测效果

```bash
# 在GPU上预测一张图片
export CUDA_VISIBLE_DEVICES=0
python tools/infer.py -c configs/ppyolo/ppyolo_r50vd_dcn_1x_coco.yml -o use_gpu=true weights=https://paddledet.bj.bcebos.com/models/ppyolo_r50vd_dcn_1x_coco.pdparams --infer_img=demo/000000014439.jpg
```

会在`output`文件夹下生成一个画有预测结果的同名图像。

结果如下图：![[000000014439.jpg]]


# 四、快速体验 - 训练

PaddleDetection作为成熟的目标检测开发套件，提供了从数据准备、模型训练、模型评估、模型导出到模型部署的全流程。在这个章节里面，我们以路标检测数据集为例，提供快速上手PaddleDetection的流程。

## 1. 准备数据
目前PaddleDetection支持：COCO VOC WiderFace, MOT四种数据格式。
- 首先按照准备数据。  
- 然后设置`configs/datasets`中相应的coco或voc等数据配置文件中的数据路径。
- 在本项目中，我们使用路标识别数据集
	```bash
	python dataset/roadsign_voc/download_roadsign_voc.py
	```
- 下载后的数据格式为
	```
	├── download_roadsign_voc.py
	├── annotations
	│   ├── road0.xml
	│   ├── road1.xml
	│   |   ...
	├── images
	│   ├── road0.png
	│   ├── road1.png
	│   |   ...
	├── label_list.txt
	├── train.txt
	├── valid.txt
	```

## 2. 配置文件改动和说明
我们使用`configs/yolov3/yolov3_mobilenet_v1_roadsign`配置进行训练。
在静态图版本下，一个模型往往可以通过两个配置文件（一个主配置文件、一个reader的读取配置）实现，在PaddleDetection 2.0后续版本，采用了模块解耦设计，用户可以组合配置模块实现检测器，并可自由修改覆盖各模块配置，如下图所示
![[Pasted image 20240805112655.png]]

从上图看到`yolov3_mobilenet_v1_roadsign.yml`配置需要依赖其他的配置文件。在该例子中需要依赖：

```bash
  roadsign_voc.yml

  runtime.yml

  optimizer_40e.yml

  yolov3_mobilenet_v1.yml

  yolov3_reader.yml
--------------------------------------


yolov3_mobilenet_v1_roadsign 文件入口

roadsign_voc 主要说明了训练数据和验证数据的路径

runtime.yml 主要说明了公共的运行参数，比如说是否使用GPU、每多少个epoch存储checkpoint等

optimizer_40e.yml 主要说明了学习率和优化器的配置。

ppyolov2_r50vd_dcn.yml 主要说明模型、和主干网络的情况。

ppyolov2_reader.yml 主要说明数据读取器配置，如batch size，并发加载子进程数等，同时包含读取后预处理操作，如resize、数据增强等等


```

![[Pasted image 20240805112712.png]]
### 修改配置文件说明
* 关于数据的路径修改说明
	在修改配置文件中，用户如何实现自定义数据集是非常关键的一步，如何定义数据集请参考[如何自定义数据集](https://aistudio.baidu.com/aistudio/projectdetail/1917140)
* 默认学习率是适配多GPU训练(8x GPU)，若使用单GPU训练，须对应调整学习率（例如，除以8）

## 3. 训练

PaddleDetection提供了单卡/多卡训练模式，满足用户多种训练需求
* GPU单卡训练
	```bash
	export CUDA_VISIBLE_DEVICES=0 #windows和Mac下不需要执行该命令
	python tools/train.py -c configs/yolov3/yolov3_mobilenet_v1_roadsign.yml
	```

* GPU多卡训练
	```bash
	export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 #windows和Mac下不需要执行该命令
	python -m paddle.distributed.launch --gpus 0,1,2,3,4,5,6,7 tools/train.py -c configs/yolov3/yolov3_mobilenet_v1_roadsign.yml
	```

* [GPU多机多卡训练](./DistributedTraining_cn.md)
	```bash
	$fleetrun \
	--ips="10.127.6.17,10.127.5.142,10.127.45.13,10.127.44.151" \
	--selected_gpu 0,1,2,3,4,5,6,7 \
	tools/train.py -c configs/yolov3/yolov3_mobilenet_v1_roadsign.yml \
	```

* Fine-tune其他任务

  使用预训练模型fine-tune其他任务时，可以直接加载预训练模型，形状不匹配的参数将自动忽略，例如：
	```bash
	export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
	  # 如果模型中参数形状与加载权重形状不同，将不会加载这类参数
	python -m paddle.distributed.launch --gpus 0,1,2,3,4,5,6,7 tools/train.py -c configs/yolov3/yolov3_mobilenet_v1_roadsign.yml -o pretrain_weights=output/model_final
	```

* 模型恢复训练

  在日常训练过程中，有的用户由于一些原因导致训练中断，用户可以使用-r的命令恢复训练
	```bash
	export CUDA_VISIBLE_DEVICES=0 #windows和Mac下不需要执行该命令
	python tools/train.py -c configs/yolov3/yolov3_mobilenet_v1_roadsign.yml -r output/faster_rcnn_r50_1x_coco/10000
	```

## 4. 评估
* 默认将训练生成的模型保存在当前`output`文件夹下
	 ```bash
	export CUDA_VISIBLE_DEVICES=0 #windows和Mac下不需要执行该命令
	python tools/eval.py -c configs/yolov3/yolov3_mobilenet_v1_roadsign.yml -o weights=https://paddledet.bj.bcebos.com/models/yolov3_mobilenet_v1_roadsign.pdparams
	```
* 边训练，边评估
	```bash
	export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 #windows和Mac下不需要执行该命令
	python -m paddle.distributed.launch --gpus 0,1,2,3,4,5,6,7 tools/train.py -c configs/yolov3/yolov3_mobilenet_v1_roadsign.yml --eval
	```

  在训练中交替执行评估, 评估在每个epoch训练结束后开始。每次评估后还会评出最佳mAP模型保存到`best_model`文件夹下。

  如果验证集很大，测试将会比较耗时，建议调整`configs/runtime.yml` 文件中的 `snapshot_epoch`配置以减少评估次数，或训练完成后再进行评估。

- 通过json文件评估
	```bash
	export CUDA_VISIBLE_DEVICES=0 #windows和Mac下不需要执行该命令
	python tools/eval.py -c configs/yolov3/yolov3_mobilenet_v1_roadsign.yml \
	             --json_eval \
	             -output_eval evaluation/
	```
* 上述命令中没有加载模型的选项，则使用配置文件中weights的默认配置，`weights`表示训练过程中保存的最后一轮模型文件

* json文件必须命名为bbox.json或者mask.json，放在`evaluation`目录下。

## 5. 预测

```bash
python tools/infer.py -c configs/yolov3/yolov3_mobilenet_v1_roadsign.yml --infer_img=demo/road554.png -o weights=https://paddledet.bj.bcebos.com/models/yolov3_mobilenet_v1_roadsign.pdparams
```
 * 设置参数预测
	```bash
	export CUDA_VISIBLE_DEVICES=0 #windows和Mac下不需要执行该命令
	python tools/infer.py -c configs/yolov3/yolov3_mobilenet_v1_roadsign.yml \
					  --infer_img=demo/road554.png \
					  --output_dir=infer_output/ \
					  --draw_threshold=0.5 \
					  -o weights=output/yolov3_mobilenet_v1_roadsign/model_final \
					  --use_vdl=True
	```

  `--draw_threshold` 是个可选参数. 根据 [NMS](https://ieeexplore.ieee.org/document/1699659) 的计算，不同阈值会产生不同的结果
  `keep_top_k`表示设置输出目标的最大数量，默认值为100，用户可以根据自己的实际情况进行设定。

结果如下图：
![[road554.png]]
## 6. 训练可视化

当打开`use_vdl`开关后，为了方便用户实时查看训练过程中状态，PaddleDetection集成了VisualDL可视化工具，当打开`use_vdl`开关后，记录的数据包括：
1. loss变化趋势
2. mAP变化趋势

```bash
export CUDA_VISIBLE_DEVICES=0 #windows和Mac下不需要执行该命令
python tools/train.py -c configs/yolov3/yolov3_mobilenet_v1_roadsign.yml
                        --use_vdl=true \
                        --vdl_log_dir=vdl_dir/scalar \
```

<!-- 
python3 -m paddle.distributed.launch --gpus 0,1 tools/train.py -c configs/yolov3_mouse_other/main.yml --eval -use_vdl=true --vdl_log_dir=vdl_dir/scalar
-->

使用如下命令启动VisualDL查看日志
```shell
# 下述命令会在127.0.0.1上启动一个服务，支持通过前端web页面查看，可以通过--host这个参数指定实际ip地址
visualdl --logdir vdl_dir/scalar/
```

在浏览器输入提示的网址，效果如下：
<center><img src="https://ai-studio-static-online.cdn.bcebos.com/ab767a202f084d1589f7d34702a75a7ef5d0f0a7e8c445bd80d54775b5761a8d" width="900" ></center>

<br><center>图：VDL效果演示</center>

**参数列表**

以下列表可以通过`--help`查看

|         FLAG             |     支持脚本    |        用途        |      默认值       |         备注         |
| :----------------------: | :------------: | :---------------: | :--------------: | :-----------------: |
|          -c              |      ALL       |  指定配置文件  |  None  |  **必选**，例如-c configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.yml |
|          -o              |      ALL       |  设置或更改配置文件里的参数内容  |  None  |  相较于`-c`设置的配置文件有更高优先级，例如：`-o use_gpu=False`  |
|        --eval            |     train      |  是否边训练边测试  |  False  |  如需指定，直接`--eval`即可 |
|   -r/--resume_checkpoint |     train      |  恢复训练加载的权重路径  |  None  |  例如：`-r output/faster_rcnn_r50_1x_coco/10000`  |
|       --slim_config             |     ALL      |  模型压缩策略配置文件  |  None  |  例如`--slim_config configs/slim/prune/yolov3_prune_l1_norm.yml`  |
|        --use_vdl          |   train/infer   |  是否使用[VisualDL](https://github.com/paddlepaddle/visualdl)记录数据，进而在VisualDL面板中显示  |  False  |  VisualDL需Python>=3.5   |
|        --vdl\_log_dir     |   train/infer   |  指定 VisualDL 记录数据的存储路径  |  train:`vdl_log_dir/scalar` infer: `vdl_log_dir/image`  |  VisualDL需Python>=3.5   |
|      --output_eval       |   eval |  评估阶段保存json路径  | None  |  例如 `--output_eval=eval_output`, 默认为当前路径  |
|       --json_eval        |       eval     |  是否通过已存在的bbox.json或者mask.json进行评估  |  False  |  如需指定，直接`--json_eval`即可， json文件路径在`--output_eval`中设置  |
|      --classwise         |       eval     |  是否评估单类AP和绘制单类PR曲线  |  False  |  如需指定，直接`--classwise`即可 |
|       --output_dir       |      infer/export_model     |  预测后结果或导出模型保存路径  |  `./output`  |  例如`--output_dir=output`  |
|    --draw_threshold      |      infer     |  可视化时分数阈值  |  0.5  |  例如`--draw_threshold=0.7`  |
|      --infer_dir         |       infer     |  用于预测的图片文件夹路径  |  None  |    `--infer_img`和`--infer_dir`必须至少设置一个 |
|      --infer_img         |       infer     |  用于预测的图片路径  |  None  |  `--infer_img`和`--infer_dir`必须至少设置一个，`infer_img`具有更高优先级  |
|      --save_results         |       infer     |  是否在文件夹下将图片的预测结果保存到文件中        |  False  |  可选  |


## 7. 模型导出

在模型训练过程中保存的模型文件是包含前向预测和反向传播的过程，在实际的工业部署则不需要反向传播，因此需要将模型进行导成部署需要的模型格式。
在PaddleDetection中提供了 `tools/export_model.py`脚本来导出模型

```bash
python tools/export_model.py -c configs/yolov3/yolov3_mobilenet_v1_roadsign.yml --output_dir=./inference_model \
 -o weights=output/yolov3_mobilenet_v1_roadsign/best_model
```
预测模型会导出到`inference_model/yolov3_mobilenet_v1_roadsign`目录下，分别为`infer_cfg.yml`, `model.pdiparams`, `model.pdiparams.info`,`model.pdmodel` 如果不指定文件夹，模型则会导出在`output_inference`

* 更多关于模型导出的文档，请参考[模型导出文档](../../deploy/EXPORT_MODEL.md)

## 8. 模型压缩

为了进一步对模型进行优化，PaddleDetection提供了基于PaddleSlim进行模型压缩的完整教程和benchmark。目前支持的方案：
* 裁剪
* 量化
* 蒸馏
* 联合策略
* 更多关于模型压缩的文档，请参考[模型压缩文档](../../configs/slim/README.md)。
## 9. 预测部署
PaddleDetection提供了PaddleInference、PaddleServing、PaddleLite多种部署形式，支持服务端、移动端、嵌入式等多种平台，提供了完善的Python和C++部署方案。
* 在这里，我们以Python为例，说明如何使用PaddleInference进行模型部署
```bash
python deploy/python/infer.py --model_dir=./output_inference/yolov3_mobilenet_v1_roadsign --image_file=demo/road554.png --device=GPU
```
* 同时`infer.py`提供了丰富的接口，用户进行接入视频文件、摄像头进行预测，更多内容请参考[Python端预测部署](../../deploy/python)





# 附录
## 常见问题
### 运行paddle.utils.run_check()时，paddle无法找到`GLIBCXX_3.4.30`

当系统中无法找到`GLIBCXX_3.4.30`时，可以通过使用Conda环境中的libstdc++库来解决这个问题。下面是详细步骤：

1. **安装Anaconda**：

   下载并安装Anaconda。

   ```bash
   wget https://repo.anaconda.com/archive/Anaconda3-2023.07-Linux-x86_64.sh
   bash Anaconda3-2023.07-Linux-x86_64.sh
   ```

2. **创建并激活Conda环境**：

   ```bash
   conda create -n paddle_env python=3.8
   conda activate paddle_env
   ```

3. **从conda-forge安装更新的libstdc++**：

   ```bash
   conda install -c conda-forge libstdcxx-ng
   ```

4. **查找Conda环境中的libstdc++库路径**：

   ```bash
   find $CONDA_PREFIX -name libstdc++.so.6
   ```

5. **验证GLIBCXX版本**：

   ```bash
   strings $CONDA_PREFIX/lib/libstdc++.so.6 | grep GLIBCXX
   ```

6. **设置.bashrc文件**：

   ```bash
   echo 'export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$LD_LIBRARY_PATH' >> ~/.bashrc
   source ~/.bashrc
   ```

7. **安装PaddlePaddle**：

   ```bash
   pip install paddlepaddle
   ```

8. **验证PaddlePaddle**：

   ```bash
   python -c "import paddle; paddle.utils.run_check()"
   ```

通过这些步骤，你可以确保系统使用Conda环境中的libstdc++库，并解决`GLIBCXX_3.4.30`相关的问题。如果有任何问题，请告诉我。



## 补充资料

### 如何检查当前服务器系统信息
首先，我们有必要先检查当前服务器的系统信息，包括内核版本、硬件配置等，有助于我们了解服务器配置。可以使用以下命令：

- 查看操作系统信息
	```bash
	cat /etc/os-release
	```
	输出结果如下，可以看到服务器运行的是Ubuntu 18.04 LTS版本：![[Pasted image 20240731133642.png]]

- 查看内核版本
	```bash
	uname -r
	```
	输出结果如下，服务器运行的内核版本为4.15.0-213-generic：![[Pasted image 20240731133803.png]]


- 查看CPU信息
	```bash
	lscpu
	```
	输出结果如下，可以看到CPU的详细信息，包括架构、核心数、线程数、频率等：
	```plaintext
	Architecture:        x86_64
	CPU op-mode(s):      32-bit, 64-bit
	Byte Order:          Little Endian
	CPU(s):              80
	On-line CPU(s) list: 0-79
	Thread(s) per core:  2
	Core(s) per socket:  20
	Socket(s):           2
	NUMA node(s):        2
	Vendor ID:           GenuineIntel
	CPU family:          6
	Model:               106
	Model name:          Intel(R) Xeon(R) Silver 4316 CPU @ 2.30GHz
	Stepping:            6
	CPU MHz:             800.781
	CPU max MHz:         3400.0000
	CPU min MHz:         800.0000
	BogoMIPS:            4600.00
	Virtualization:      VT-x
	L1d cache:           48K
	L1i cache:           32K
	L2 cache:            1280K
	L3 cache:            30720K
	NUMA node0 CPU(s):   0-19,40-59
	NUMA node1 CPU(s):   20-39,60-79
	Flags:               ...
	```

- 查看内存信息
	```bash
	free -h
	```
	输出结果如下，可以看到服务器的内存和swap配置：![[Pasted image 20240731134757.png]]


- 查看显卡信息
	```bash
	nvidia-smi
	```
	输出结果如下，可以看到服务器上的NVIDIA显卡型号及相关信息：![[Pasted image 20240731134815.png]]
